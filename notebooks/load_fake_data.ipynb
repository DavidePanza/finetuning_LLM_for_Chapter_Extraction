{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4f8fb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "import json\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3090a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect data\n",
    "# doc = Document(\"../synthetic_data/docx/2_chapter.docx\")\n",
    "\n",
    "# # Every paragraph (including headings)\n",
    "# docx_text = \"\\n\".join(p.text for p in doc.paragraphs if p.text.strip())\n",
    "\n",
    "# # Every paragraph (including headings)\n",
    "# for p in doc.paragraphs:\n",
    "#     print(p.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a71393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_structured_toc(text):\n",
    "    lines = [line.strip() for line in text.strip().splitlines() if line.strip()]\n",
    "    books = []\n",
    "    \n",
    "    current_book = None\n",
    "    current_chapter = None\n",
    "    \n",
    "    # Regex patterns\n",
    "    book_title_re = re.compile(r\"^(\\d+)\\.\\s+(.+)\", re.IGNORECASE)\n",
    "    chapter_re = chapter_re = re.compile(r\"^[â€¢\\*]?\\s*Chapter\\s+(\\d+):\\s+(.+)$\", re.IGNORECASE)\n",
    "    subchapter_re = re.compile(r\"^(\\d+)\\.(\\d+)\\s+(.+)$\")\n",
    "\n",
    "    for line in lines:\n",
    "        # Check if this is a new book title\n",
    "        if (match := book_title_re.match(line)):\n",
    "            # Save previous book if exists\n",
    "            if current_book:\n",
    "                books.append(current_book)\n",
    "            \n",
    "            # Start new book\n",
    "            current_book = OrderedDict()\n",
    "            current_book[\"id\"] = int(match.group(1))\n",
    "            current_book[\"name\"] = match.group(2).strip()\n",
    "            current_book[\"chapters_counts\"] = 0\n",
    "            current_book[\"chapters\"] = []\n",
    "            current_chapter = None\n",
    "\n",
    "        # Check if this is a chapter\n",
    "        elif (match := chapter_re.match(line)) and current_book:\n",
    "            number = int(match.group(1))\n",
    "            title = match.group(2).strip()\n",
    "            current_chapter = {\n",
    "                \"number\": number,\n",
    "                \"title\": title,\n",
    "                \"subchapter_count\": 0,\n",
    "                \"subchapters\": []\n",
    "            }\n",
    "            current_book[\"chapters_counts\"] = len(current_book[\"chapters\"])\n",
    "            current_book[\"chapters\"].append(current_chapter)\n",
    "\n",
    "        # Check if this is a subchapter\n",
    "        elif (match := subchapter_re.match(line)) and current_chapter:\n",
    "            sub_number = f\"{match.group(1)}.{match.group(2)}\"\n",
    "            title = match.group(3).strip()\n",
    "            current_chapter[\"subchapters\"].append({\n",
    "                \"number\": sub_number,\n",
    "                \"title\": title\n",
    "            })\n",
    "            # Update subchapter count\n",
    "            current_chapter[\"subchapter_count\"] = len(current_chapter[\"subchapters\"])\n",
    "    # Don't forget to add the last book\n",
    "    if current_book:\n",
    "        books.append(current_book)\n",
    "\n",
    "    # If only one book, return it directly (maintains backward compatibility)\n",
    "    if len(books) == 1:\n",
    "        return books[0]\n",
    "    \n",
    "    # If multiple books, return list\n",
    "    return books\n",
    "\n",
    "\n",
    "# parsed = parse_structured_toc(docx_text)\n",
    "# print(json.dumps(parsed, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803d02d1",
   "metadata": {},
   "source": [
    "### Process text and store in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f0bdb9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../synthetic_data/docx/\"\n",
    "output_dir = \"../synthetic_data/json\"\n",
    "files = [file for file in os.listdir(data_dir) if not file.startswith(\"~\")]\n",
    "\n",
    "full_results = []\n",
    "chapters_results = []\n",
    "\n",
    "for file in files:\n",
    "    if file.endswith(\"_full.docx\"):\n",
    "        cur_path = os.path.join(data_dir, file)\n",
    "        doc = Document(cur_path)\n",
    "        docx_text = \"\\n\".join(p.text for p in doc.paragraphs if p.text.strip())\n",
    "        result = parse_structured_toc(docx_text)\n",
    "        full_results.extend(result)\n",
    "    elif file.endswith(\"_chapter.docx\"):\n",
    "        cur_path = os.path.join(data_dir, file)\n",
    "        doc = Document(cur_path)\n",
    "        docx_text = \"\\n\".join(p.text for p in doc.paragraphs if p.text.strip())\n",
    "        result = parse_structured_toc(docx_text)\n",
    "        chapters_results.extend(result)\n",
    "\n",
    "with open(os.path.join(output_dir, \"all_full.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(full_results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "with open(os.path.join(output_dir, \"all_chapters.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(chapters_results, f, indent=2, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
