{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78681171",
   "metadata": {},
   "source": [
    "# ðŸ“„ DOCX to JSON Data Processing Pipeline\n",
    "\n",
    "## Source of the Data\n",
    "\n",
    "The `.docx` files processed in this notebook were **distilled using a Large Language Model (LLM)** from complex academic and technical PDFs. This distillation step extracts structured chapter text, headings, and subheadings into a consistent format suitable for automated parsing.\n",
    "\n",
    "## What This Notebook Does\n",
    "\n",
    "- Loads `.docx` files containing chapter-based content using `python-docx`\n",
    "- Parses and cleans text, preserving paragraph structure and headings\n",
    "- **Transforms the raw `.docx` data into structured `.json` files** that can be used for further processing\n",
    "- Prepares the output to be used in later stages, such as generating synthetic noisy TOCs or training/evaluation pipelines\n",
    "\n",
    "## Adding Your Own Data\n",
    "\n",
    "You can easily extend this workflow by adding your own `.docx` files. To ensure your data is compatible:\n",
    "\n",
    "- Follow the **same formatting structure** (use clear section headings, avoid unusual indentation or styles)\n",
    "- Save your files to the `synthetic_data/docx/` directory\n",
    "- The parser expects documents to be organized with **consistent, LLM-friendly formatting**, as seen in the original examples\n",
    "\n",
    "Once added, your `.docx` file will be parsed and included in the same JSON-based transformation process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247b9f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "from distilled_data_processing.toc_parsing import parse_structured_toc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6eaec2",
   "metadata": {},
   "source": [
    "## Inspecting a Sample `.docx`\n",
    "\n",
    "Load a `.docx` file, extract all non-empty paragraphs, and print them to inspect the document structure.  \n",
    "Then parse the text into a structured JSON format using `parse_structured_toc` and print the result for review.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3090a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Artificial Intelligence and Machine Learning\n",
      "Chapter 1: Introduction to Artificial Intelligence\n",
      "Chapter 2: Machine Learning Fundamentals\n",
      "Chapter 3: Neural Networks and Deep Learning\n",
      "Chapter 4: Computer Vision Applications\n",
      "Chapter 5: Natural Language Processing\n",
      "Chapter 6: Reinforcement Learning Systems\n",
      "Chapter 7: AI Ethics and Bias Prevention\n",
      "Chapter 8: Automated Decision Making\n",
      "Chapter 9: AI in Healthcare and Medicine\n"
     ]
    }
   ],
   "source": [
    "# Inspect data\n",
    "doc = Document(\"../synthetic_data/docx/2_chapter.docx\")\n",
    "\n",
    "# Every paragraph (including headings)\n",
    "docx_text = \"\\n\".join(p.text for p in doc.paragraphs if p.text.strip())\n",
    "\n",
    "# Every paragraph (including headings)\n",
    "for p in doc.paragraphs[:10]:\n",
    "    print(p.text)\n",
    "\n",
    "# Inspect final json format\n",
    "parsed = parse_structured_toc(docx_text)\n",
    "print(json.dumps(parsed, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803d02d1",
   "metadata": {},
   "source": [
    "## Process text and store in local directory\n",
    "Lists `.docx` files in the source directory, filters out temporary files, and processes files ending with `_full.docx` and `_chapter.docx` separately. Each document is loaded, its non-empty paragraphs extracted, and parsed into structured TOC data using `parse_structured_toc`. The parsed results are collected and saved as JSON files in the output directory for further use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bdb9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../synthetic_data/docx/\"\n",
    "output_dir = \"../synthetic_data/json\"\n",
    "files = [file for file in os.listdir(data_dir) if not file.startswith(\"~\")]\n",
    "\n",
    "full_results = []\n",
    "chapters_results = []\n",
    "\n",
    "for file in files:\n",
    "    if file.endswith(\"_full.docx\"):\n",
    "        cur_path = os.path.join(data_dir, file)\n",
    "        doc = Document(cur_path)\n",
    "        docx_text = \"\\n\".join(p.text for p in doc.paragraphs if p.text.strip())\n",
    "        result = parse_structured_toc(docx_text)\n",
    "        full_results.extend(result)\n",
    "    elif file.endswith(\"_chapter.docx\"):\n",
    "        cur_path = os.path.join(data_dir, file)\n",
    "        doc = Document(cur_path)\n",
    "        docx_text = \"\\n\".join(p.text for p in doc.paragraphs if p.text.strip())\n",
    "        result = parse_structured_toc(docx_text)\n",
    "        chapters_results.extend(result)\n",
    "\n",
    "with open(os.path.join(output_dir, \"all_full.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(full_results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "with open(os.path.join(output_dir, \"all_chapters.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(chapters_results, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d0ff3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
