{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6a90178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "95cdc857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents\n",
      "Foreword\n",
      "1\n",
      "Part I\n",
      "Mathematical Foundations\n",
      "9\n",
      "1\n",
      "Introduction and Motivation\n",
      "11\n",
      "1.1\n",
      "Finding Words for Intuitions\n",
      "12\n",
      "1.2\n",
      "Two Ways to Read This Book\n",
      "13\n",
      "1.3\n",
      "Exercises and Feedback\n",
      "16\n",
      "2\n",
      "Linear Algebra\n",
      "17\n",
      "2.1\n",
      "Systems of Linear Equations\n",
      "19\n",
      "2.2\n",
      "Matrices\n",
      "22\n",
      "2.3\n",
      "Solving Systems of Linear Equations\n",
      "27\n",
      "2.4\n",
      "Vector Spaces\n",
      "35\n",
      "2.5\n",
      "Linear Independence\n",
      "40\n",
      "2.6\n",
      "Basis and Rank\n",
      "44\n",
      "2.7\n",
      "Linear Mappings\n",
      "48\n",
      "2.8\n",
      "Afﬁne Spaces\n",
      "61\n",
      "2.9\n",
      "Further Reading\n",
      "63\n",
      "Exercises\n",
      "64\n",
      "3\n",
      "Analytic Geometry\n",
      "70\n",
      "3.1\n",
      "Norms\n",
      "71\n",
      "3.2\n",
      "Inner Products\n",
      "72\n",
      "3.3\n",
      "Lengths and Distances\n",
      "75\n",
      "3.4\n",
      "Angles and Orthogonality\n",
      "76\n",
      "3.5\n",
      "Orthonormal Basis\n",
      "78\n",
      "3.6\n",
      "Orthogonal Complement\n",
      "79\n",
      "3.7\n",
      "Inner Product of Functions\n",
      "80\n",
      "3.8\n",
      "Orthogonal Projections\n",
      "81\n",
      "3.9\n",
      "Rotations\n",
      "91\n",
      "3.10\n",
      "Further Reading\n",
      "94\n",
      "Exercises\n",
      "96\n",
      "4\n",
      "Matrix Decompositions\n",
      "98\n",
      "4.1\n",
      "Determinant and Trace\n",
      "99\n",
      "i\n",
      "This material will be published by Cambridge University Press as Mathematics for Machine Learn-\n",
      "ing by Marc Peter Deisenroth, A. Aldo Faisal, and Cheng Soon Ong. This pre-publication version is\n",
      "free to view and download for personal use only. Not for re-distribution, re-sale or use in deriva-\n",
      "tive works. c⃝by M. P. Deisenroth, A. A. Faisal, and C. S. Ong, 2019. https://mml-book.com.\n",
      "\n",
      "ii\n",
      "Contents\n",
      "4.2\n",
      "Eigenvalues and Eigenvectors\n",
      "105\n",
      "4.3\n",
      "Cholesky Decomposition\n",
      "114\n",
      "4.4\n",
      "Eigendecomposition and Diagonalization\n",
      "115\n",
      "4.5\n",
      "Singular Value Decomposition\n",
      "119\n",
      "4.6\n",
      "Matrix Approximation\n",
      "129\n",
      "4.7\n",
      "Matrix Phylogeny\n",
      "134\n",
      "4.8\n",
      "Further Reading\n",
      "135\n",
      "Exercises\n",
      "137\n",
      "5\n",
      "Vector Calculus\n",
      "139\n",
      "5.1\n",
      "Differentiation of Univariate Functions\n",
      "141\n",
      "5.2\n",
      "Partial Differentiation and Gradients\n",
      "146\n",
      "5.3\n",
      "Gradients of Vector-Valued Functions\n",
      "149\n",
      "5.4\n",
      "Gradients of Matrices\n",
      "155\n",
      "5.5\n",
      "Useful Identities for Computing Gradients\n",
      "158\n",
      "5.6\n",
      "Backpropagation and Automatic Differentiation\n",
      "159\n",
      "5.7\n",
      "Higher-Order Derivatives\n",
      "164\n",
      "5.8\n",
      "Linearization and Multivariate Taylor Series\n",
      "165\n",
      "5.9\n",
      "Further Reading\n",
      "170\n",
      "Exercises\n",
      "170\n",
      "6\n",
      "Probability and Distributions\n",
      "172\n",
      "6.1\n",
      "Construction of a Probability Space\n",
      "172\n",
      "6.2\n",
      "Discrete and Continuous Probabilities\n",
      "178\n",
      "6.3\n",
      "Sum Rule, Product Rule, and Bayes’ Theorem\n",
      "183\n",
      "6.4\n",
      "Summary Statistics and Independence\n",
      "186\n",
      "6.5\n",
      "Gaussian Distribution\n",
      "197\n",
      "6.6\n",
      "Conjugacy and the Exponential Family\n",
      "205\n",
      "6.7\n",
      "Change of Variables/Inverse Transform\n",
      "214\n",
      "6.8\n",
      "Further Reading\n",
      "221\n",
      "Exercises\n",
      "222\n",
      "7\n",
      "Continuous Optimization\n",
      "225\n",
      "7.1\n",
      "Optimization Using Gradient Descent\n",
      "227\n",
      "7.2\n",
      "Constrained Optimization and Lagrange Multipliers\n",
      "233\n",
      "7.3\n",
      "Convex Optimization\n",
      "236\n",
      "7.4\n",
      "Further Reading\n",
      "246\n",
      "Exercises\n",
      "247\n",
      "Part II\n",
      "Central Machine Learning Problems\n",
      "249\n",
      "8\n",
      "When Models Meet Data\n",
      "251\n",
      "8.1\n",
      "Data, Models, and Learning\n",
      "251\n",
      "8.2\n",
      "Empirical Risk Minimization\n",
      "258\n",
      "8.3\n",
      "Parameter Estimation\n",
      "265\n",
      "8.4\n",
      "Probabilistic Modeling and Inference\n",
      "272\n",
      "8.5\n",
      "Directed Graphical Models\n",
      "278\n",
      "Draft (2019-12-11) of “Mathematics for Machine Learning”. Feedback: https://mml-book.com.\n",
      "\n",
      "Contents\n",
      "iii\n",
      "8.6\n",
      "Model Selection\n",
      "283\n",
      "9\n",
      "Linear Regression\n",
      "289\n",
      "9.1\n",
      "Problem Formulation\n",
      "291\n",
      "9.2\n",
      "Parameter Estimation\n",
      "292\n",
      "9.3\n",
      "Bayesian Linear Regression\n",
      "303\n",
      "9.4\n",
      "Maximum Likelihood as Orthogonal Projection\n",
      "313\n",
      "9.5\n",
      "Further Reading\n",
      "315\n",
      "10\n",
      "Dimensionality Reduction with Principal Component Analysis\n",
      "317\n",
      "10.1\n",
      "Problem Setting\n",
      "318\n",
      "10.2\n",
      "Maximum Variance Perspective\n",
      "320\n",
      "10.3\n",
      "Projection Perspective\n",
      "325\n",
      "10.4\n",
      "Eigenvector Computation and Low-Rank Approximations\n",
      "333\n",
      "10.5\n",
      "PCA in High Dimensions\n",
      "335\n",
      "10.6\n",
      "Key Steps of PCA in Practice\n",
      "336\n",
      "10.7\n",
      "Latent Variable Perspective\n",
      "339\n",
      "10.8\n",
      "Further Reading\n",
      "343\n",
      "11\n",
      "Density Estimation with Gaussian Mixture Models\n",
      "348\n",
      "11.1\n",
      "Gaussian Mixture Model\n",
      "349\n",
      "11.2\n",
      "Parameter Learning via Maximum Likelihood\n",
      "350\n",
      "11.3\n",
      "EM Algorithm\n",
      "360\n",
      "11.4\n",
      "Latent-Variable Perspective\n",
      "363\n",
      "11.5\n",
      "Further Reading\n",
      "368\n",
      "12\n",
      "Classiﬁcation with Support Vector Machines\n",
      "370\n",
      "12.1\n",
      "Separating Hyperplanes\n",
      "372\n",
      "12.2\n",
      "Primal Support Vector Machine\n",
      "374\n",
      "12.3\n",
      "Dual Support Vector Machine\n",
      "383\n",
      "12.4\n",
      "Kernels\n",
      "388\n",
      "12.5\n",
      "Numerical Solution\n",
      "390\n",
      "12.6\n",
      "Further Reading\n",
      "392\n",
      "References\n",
      "395\n",
      "Index\n",
      "407\n",
      "c⃝2019 M. P. Deisenroth, A. A. Faisal, C. S. Ong. To be published by Cambridge University Press.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dictionary mapping example keys to PDF paths\n",
    "examples = {\n",
    "    \"pdf_path1\": \"../data/mcelreath_2020_statistical-rethinking.pdf\",\n",
    "    \"pdf_path2\": \"../data/Theory of Statistic.pdf\",\n",
    "    \"pdf_path3\": \"../data/Deep Learning with Python.pdf\",\n",
    "    \"pdf_path4\": \"../data/Natural_Image_Statistics.pdf\",\n",
    "    \"pdf_path5\": \"../data/mml-book.pdf\"\n",
    "}\n",
    "\n",
    "# Dictionary mapping example keys to page ranges to extract content from\n",
    "content_page_ranges = {\n",
    "    \"pdf_path1\": range(5, 8),\n",
    "    \"pdf_path2\": range(10, 17),\n",
    "    \"pdf_path3\": range(7, 13),\n",
    "    \"pdf_path4\": range(4, 13),\n",
    "    \"pdf_path5\": range(2, 5),\n",
    "}\n",
    "\n",
    "# Select example number\n",
    "n_example = 5\n",
    "key = f\"pdf_path{n_example}\"\n",
    "\n",
    "# Open the PDF\n",
    "doc = fitz.open(examples[key])\n",
    "\n",
    "# Extract text from the specified page range\n",
    "chapters_content_list = []\n",
    "for page_num in content_page_ranges[key]:\n",
    "    page = doc[page_num]\n",
    "    text = page.get_text(\"text\")\n",
    "    chapters_content_list.append(text)\n",
    "\n",
    "# Join all text pages into a single string if needed\n",
    "chapters_content = \"\\n\".join(chapters_content_list)\n",
    "\n",
    "print(chapters_content)  # or pass it to your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5dbbfa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_font_info(pdf_path, header_margin=70, footer_margin=100):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    font_data = []\n",
    "    \n",
    "    for page_num in content_page_ranges[key]:\n",
    "        page = doc.load_page(page_num)\n",
    "        page_height = page.rect.height\n",
    "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "        \n",
    "        for block in blocks:\n",
    "            if \"lines\" in block:\n",
    "                for line in block[\"lines\"]:\n",
    "                    for span in line[\"spans\"]:\n",
    "                        y = span[\"origin\"][1]\n",
    "                        # Skip headers/footers using defaults\n",
    "                        if y < header_margin or y > (page_height - footer_margin):\n",
    "                            continue\n",
    "                        font_data.append({\n",
    "                            \"text\": span[\"text\"],\n",
    "                            # \"font_name\": span[\"font\"],\n",
    "                            # \"font_size\": span[\"size\"],\n",
    "                            # \"color\": span[\"color\"],  # RGB tuple (e.g., (0, 0, 0) for black)\n",
    "                            # \"is_bold\": \"bold\" in span[\"font\"].lower(),\n",
    "                            # \"is_italic\": \"italic\" in span[\"font\"].lower(),\n",
    "                            \"page\": page_num + 1,\n",
    "                            \"coordinates\": (span[\"origin\"][0], span[\"origin\"][1])\n",
    "                        })\n",
    "    return font_data\n",
    "\n",
    "\n",
    "def extract_lines_from_font_info(font_info):\n",
    "    \"\"\"\n",
    "    Extracts lines of text from font information based on y-coordinates.\n",
    "    This function assumes that text elements with the same y-coordinate belong to the same line.\n",
    "    \"\"\"\n",
    "    if not font_info:\n",
    "        return []\n",
    "    lines = []\n",
    "    prev_y = None\n",
    "    cur_line = \"\"\n",
    "\n",
    "    for element in font_info:\n",
    "        cur_y = element['coordinates'][1]\n",
    "        if prev_y is None or cur_y == prev_y:\n",
    "            cur_line += \" \" + element['text']\n",
    "        else:\n",
    "            if cur_line.strip():\n",
    "                lines.append(cur_line.strip())\n",
    "            cur_line = element['text']\n",
    "        prev_y = cur_y\n",
    "\n",
    "    # Don't forget the last line\n",
    "    if cur_line.strip():\n",
    "        lines.append(cur_line.strip())\n",
    "\n",
    "    return lines\n",
    "\n",
    "\n",
    "class TextCleaner:\n",
    "    def __init__(self):\n",
    "        self.patterns = {\n",
    "            'numbered_lines': re.compile(r'^\\d+\\.\\d+\\b'),\n",
    "            'symbol_only': re.compile(r'^[\\W_]+$'),\n",
    "            'copyright_pattern': re.compile(r'(©|ⓒ|\\(c\\)|\\(C\\)|c\\s*⃝)', re.IGNORECASE),\n",
    "            'exercises_pattern': re.compile(r'^\\s*Exercises?\\b[\\s\\d.:!?-]*$', re.IGNORECASE),\n",
    "            'dotted_noise': re.compile(r'(?<!\\w)([.\\s]){3,}(?!\\w)'),  \n",
    "            'symbol_noise': re.compile(r'(?<!\\w)([\\W]\\s?){3,}(?!\\w)')\n",
    "            }\n",
    "\n",
    "    def filter_lines(self, lines):\n",
    "        \"\"\"Remove unwanted lines while keeping the structure\"\"\"\n",
    "        return [\n",
    "            line for line in lines\n",
    "            if not (self.patterns['numbered_lines'].match(line.strip()) or \n",
    "                   self.patterns['symbol_only'].match(line.strip()) or\n",
    "                   self.patterns['copyright_pattern'].search(line.strip()) or\n",
    "                   self.patterns['exercises_pattern'].match(line.strip())) \n",
    "        ]\n",
    "\n",
    "    def filter_noise(self, lines):\n",
    "        \"\"\"Remove noise patterns from lines\"\"\"\n",
    "        cleaned = []\n",
    "        for line in lines:\n",
    "            # Remove standalone noise sequences (not between words)\n",
    "            line = self.patterns['dotted_noise'].sub('', line)\n",
    "            line = self.patterns['symbol_noise'].sub('', line)\n",
    "            cleaned.append(line.strip())\n",
    "        return cleaned\n",
    "    \n",
    "    def process(self, lines):\n",
    "        \"\"\"Complete processing pipeline\"\"\"\n",
    "        filtered = self.filter_lines(lines)\n",
    "        cleaned = self.filter_noise(filtered)\n",
    "        return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "08507f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents\n",
      "Foreword 1\n",
      "Part I Mathematical Foundations 9\n",
      "1 Introduction and Motivation 11\n",
      "2 Linear Algebra 17\n",
      "3 Analytic Geometry 70\n",
      "4 Matrix Decompositions 98\n",
      "i\n",
      "This material will be published by Cambridge University Press as  Mathematics for Machine Learn-\n",
      "ii Contents\n",
      "5 Vector Calculus 139\n",
      "6 Probability and Distributions 172\n",
      "7 Continuous Optimization 225\n",
      "Part II Central Machine Learning Problems 249\n",
      "8 When Models Meet Data 251\n",
      "Draft (2019-12-11) of “Mathematics for Machine Learning”. Feedback:  https://mml-book.com .\n",
      "Contents iii\n",
      "9 Linear Regression 289\n",
      "10 Dimensionality Reduction with Principal Component Analysis 317\n",
      "11 Density Estimation with Gaussian Mixture Models 348\n",
      "12 Classiﬁcation with Support Vector Machines 370\n",
      "References 395\n",
      "Index 407\n",
      "c\n",
      "⃝ 2019 M. P. Deisenroth, A. A. Faisal, C. S. Ong. To be published by Cambridge University Press.\n"
     ]
    }
   ],
   "source": [
    "font_info = extract_font_info(examples[key])\n",
    "lines = extract_lines_from_font_info(font_info)\n",
    "cleaner = TextCleaner()\n",
    "processed_lines = cleaner.process(lines)\n",
    "\n",
    "for line in processed_lines:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad1325d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2a3197",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
